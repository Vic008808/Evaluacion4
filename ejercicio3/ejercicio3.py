# -*- coding: utf-8 -*-
"""Ejercicio3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P69EAFg9JzPe5FPBuembvt3DvHD0DTCG

# ===============================================================
# üîπ EJERCICIO 3: AN√ÅLISIS DE SENTIMIENTOS EN RESE√ëAS DE PRODUCTOS AMAZON
# Dataset: Amazon Fine Food Reviews (Kaggle)
# Objetivo: Clasificar rese√±as como positivas o negativas a partir del texto
# ===============================================================

# ===============================================================
# 1. DESCARGA E IMPORTACI√ìN DEL DATASET DESDE KAGGLE
# ===============================================================
"""

!pip install kaggle --quiet

!mkdir ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d snap/amazon-fine-food-reviews
!unzip amazon-fine-food-reviews.zip

"""# ===============================================================
# 2. CARGA INICIAL Y EXPLORACI√ìN B√ÅSICA DEL DATASET
# ===============================================================
"""

import pandas as pd

# Cargar el dataset
df = pd.read_csv('Reviews.csv')

# Mostrar dimensiones y primeras filas
print("Dimensiones del dataset:", df.shape)
df.head()

"""# ===============================================================
# 3. SELECCI√ìN DE VARIABLES Y CREACI√ìN DE ETIQUETAS
# ===============================================================
"""

df = df[['Text', 'Score']].dropna()
df = df[df['Score'] != 3]  # eliminamos rese√±as neutras
df['label'] = df['Score'].apply(lambda x: 1 if x >= 4 else 0)
df.head()

"""# ===============================================================
# 4. LIMPIEZA Y VECTORIZACI√ìN DEL TEXTO (STOPWORDS, TOKENIZACI√ìN Y TF-IDF)
# ===============================================================
"""

import re
import nltk
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

# Descargar recursos necesarios
nltk.download('stopwords')

# Funci√≥n de limpieza
def limpiar_texto(texto):
    texto = texto.lower()                             # min√∫sculas
    texto = re.sub(r'[^a-z\s]', '', texto)            # solo letras y espacios
    palabras = texto.split()
    palabras = [p for p in palabras if p not in stopwords.words('english')]
    return ' '.join(palabras)

# Aplicar limpieza (esto puede tardar un poco)
df['clean_text'] = df['Text'].apply(limpiar_texto)

# Divisi√≥n en train/test
X_train, X_test, y_train, y_test = train_test_split(
    df['clean_text'], df['label'], test_size=0.2, random_state=42
)

# Vectorizaci√≥n TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

print("Dimensiones TF-IDF:", X_train_tfidf.shape)

"""# ===============================================================
# 5. ENTRENAMIENTO Y EVALUACI√ìN DE MODELOS SUPERVISADOS
# (Naive Bayes, Logistic Regression y SVM)
# ===============================================================
"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# --- Diccionario para almacenar resultados ---
resultados = {}

# --- Modelo 1: Naive Bayes ---
nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train)
y_pred_nb = nb.predict(X_test_tfidf)
resultados['Naive Bayes'] = {
    'Accuracy': accuracy_score(y_test, y_pred_nb),
    'F1': f1_score(y_test, y_pred_nb),
    'Predicciones': y_pred_nb
}

# --- Modelo 2: Regresi√≥n Log√≠stica ---
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_tfidf, y_train)
y_pred_lr = lr.predict(X_test_tfidf)
resultados['Logistic Regression'] = {
    'Accuracy': accuracy_score(y_test, y_pred_lr),
    'F1': f1_score(y_test, y_pred_lr),
    'Predicciones': y_pred_lr
}

# --- Modelo 3: SVM ---
svm = LinearSVC()
svm.fit(X_train_tfidf, y_train)
y_pred_svm = svm.predict(X_test_tfidf)
resultados['SVM'] = {
    'Accuracy': accuracy_score(y_test, y_pred_svm),
    'F1': f1_score(y_test, y_pred_svm),
    'Predicciones': y_pred_svm
}

# --- Resultados comparativos ---
print("Resultados comparativos:\n")
for modelo, metrics in resultados.items():
    print(f"{modelo} -> Accuracy: {metrics['Accuracy']:.4f}, F1: {metrics['F1']:.4f}")

# --- Matrices de confusi√≥n individuales ---
for modelo, metrics in resultados.items():
    cm = confusion_matrix(y_test, metrics['Predicciones'])
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Matriz de Confusi√≥n - {modelo}")
    plt.xlabel("Predicho")
    plt.ylabel("Real")
    plt.show()

# --- Reporte detallado del mejor modelo (SVM) ---
print("\nReporte de Clasificaci√≥n - SVM:")
print(classification_report(y_test, resultados['SVM']['Predicciones']))

"""# ===============================================================
# 6. AN√ÅLISIS EXPLORATORIO DE DATOS (EDA): DISTRIBUCI√ìN DE PUNTAJES
# ===============================================================
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Informaci√≥n general del dataset
print("Dimensiones:", df.shape)
print("\nColumnas:\n", df.columns)
print("\nValores nulos por columna:\n", df.isnull().sum())

# Estad√≠sticas b√°sicas del puntaje
print("\nDistribuci√≥n de 'Score':")
print(df['Score'].value_counts())

# Visualizaci√≥n de la distribuci√≥n de puntajes
plt.figure(figsize=(7,4))
sns.countplot(x='Score', data=df, palette='viridis')
plt.title('Distribuci√≥n de Puntajes en Rese√±as (1-5)')
plt.show()

"""# ===============================================================
# 7. CREACI√ìN DE ETIQUETAS DE SENTIMIENTO Y VERIFICACI√ìN DE DISTRIBUCI√ìN
# ===============================================================
"""

# Eliminamos filas sin texto
df = df.dropna(subset=['Text'])

# Creamos una nueva columna 'Sentiment'
# 1 ‚Üí positiva (Score >= 4), 0 ‚Üí negativa (Score <= 2)
df = df[df['Score'] != 3]  # quitamos los neutros
df['Sentiment'] = df['Score'].apply(lambda x: 1 if x > 3 else 0)

# Verificamos distribuci√≥n
print(df['Sentiment'].value_counts())
sns.countplot(x='Sentiment', data=df, palette='coolwarm')
plt.title('Distribuci√≥n de sentimientos (0=Negativo, 1=Positivo)')
plt.show()

# Mostramos muestra de texto
df[['Text', 'Sentiment']].head()

"""# ===============================================================
# 8. REDUCCI√ìN DE DIMENSIONALIDAD Y VISUALIZACI√ìN CON t-SNE
# ===============================================================
"""

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
import random

# Tomamos una muestra aleatoria para visualizar (por rendimiento)
sample_size = 2000
indices = random.sample(range(len(X_test_tfidf.toarray())), sample_size)

X_embedded = TSNE(n_components=2, random_state=42, perplexity=40).fit_transform(X_test_tfidf[indices].toarray())
y_sample = y_test.iloc[indices].values

# Gr√°fico
plt.figure(figsize=(10, 7))
sns.scatterplot(
    x=X_embedded[:,0], y=X_embedded[:,1],
    hue=y_sample,
    palette={0: "red", 1: "green"},
    alpha=0.6
)
plt.title("Visualizaci√≥n t-SNE de rese√±as positivas (verde) y negativas (rojo)")
plt.xlabel("Componente 1")
plt.ylabel("Componente 2")
plt.show()

"""# ===============================================================
# 9. EVALUACI√ìN GR√ÅFICA CON CURVAS ROC Y √ÅREA BAJO LA CURVA (AUC)
# ===============================================================
"""

from sklearn.metrics import roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))

# Naive Bayes (usa predict_proba)
y_score_nb = nb.predict_proba(X_test_tfidf)[:,1]
fpr_nb, tpr_nb, _ = roc_curve(y_test, y_score_nb)
auc_nb = auc(fpr_nb, tpr_nb)
plt.plot(fpr_nb, tpr_nb, label=f'Naive Bayes (AUC = {auc_nb:.3f})')

# Logistic Regression (predict_proba)
y_score_lr = lr.predict_proba(X_test_tfidf)[:,1]
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_lr)
auc_lr = auc(fpr_lr, tpr_lr)
plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.3f})')

# SVM (LinearSVC -> decision_function)
y_score_svm = svm.decision_function(X_test_tfidf)
fpr_svm, tpr_svm, _ = roc_curve(y_test, y_score_svm)
auc_svm = auc(fpr_svm, tpr_svm)
plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {auc_svm:.3f})')

plt.plot([0,1],[0,1],'k--',alpha=0.4)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

print("AUCs -> NB: {:.4f}, LR: {:.4f}, SVM: {:.4f}".format(auc_nb, auc_lr, auc_svm))

"""# ===============================================================
# 10. REDUCCI√ìN DE DIMENSIONALIDAD CON TruncatedSVD
# ===============================================================
"""

from sklearn.decomposition import TruncatedSVD
import numpy as np

# Reducir TF-IDF a 2 componentes directamente con TruncatedSVD (sparse-friendly)
svd = TruncatedSVD(n_components=2, random_state=42)
X_svd = svd.fit_transform(X_test_tfidf)

plt.figure(figsize=(9,7))
sns.scatterplot(x=X_svd[:,0], y=X_svd[:,1], hue=y_test, palette={0:'red',1:'green'}, alpha=0.6)
plt.title('Visualizaci√≥n con TruncatedSVD (2 componentes) sobre TF-IDF')
plt.xlabel('Componente 1')
plt.ylabel('Componente 2')
plt.show()

"""####Descripci√≥n del Problema

Clasificar rese√±as de productos alimenticios en Amazon como positivas o negativas a partir del texto de la rese√±a. Se usa el dataset Amazon Fine Food Reviews (Reviews.csv). Este ejercicio eval√∫a limpieza de texto, extracci√≥n de caracter√≠sticas (TF-IDF), entrenamiento de modelos supervisados y an√°lisis de resultados.

- Naive Bayes (MultinomialNB): Es eficiente y robusto para texto con representaci√≥n Bag-of-Words/TF-IDF; buen baseline.

- Logistic Regression: Modelo lineal con probabilidad bien calibrada; permite regularizaci√≥n y suele ser competitivo en tareas de clasificaci√≥n de texto.

- SVM (LinearSVC): Potente para clasificaci√≥n lineal en espacios de alta dimensi√≥n (como TF-IDF); suele dar buena generalizaci√≥n cuando las clases son separables por un hiperplano.

Por qu√© estos 3:

1. Cubren enfoques probabil√≠sticos (NB),
2. Lineales probabil√≠sticos con regularizaci√≥n (LR) y
3. Margen m√°ximo (SVM).

Esto permite comparar distintos supuestos y comportamiento en el dataset.

####Resultados y m√©tricas

Resultados principales:
- SVM obtuvo mejor F1 (0.9604) y Accuracy (0.9322).
- Logistic Regression qued√≥ cercano (F1 0.9597).
- Naive Bayes, aunque m√°s r√°pido, tuvo desempe√±o inferior.

Las matrices de confusi√≥n muestran mayor dificultad para clasificar la clase negativa (menor recall) debido a desbalance.

####Conclusiones

El proyecto permiti√≥ construir un sistema de clasificaci√≥n de sentimientos aplicado a rese√±as de alimentos en Amazon.
A trav√©s de un flujo que incluy√≥ limpieza de texto, vectorizaci√≥n TF-IDF y el uso de tres modelos supervisados (Naive Bayes, Logistic Regression y SVM), se logr√≥ identificar con gran precisi√≥n las rese√±as positivas y negativas escritas por los usuarios.

Los resultados mostraron que el modelo SVM fue el m√°s efectivo, alcanzando la mayor accuracy y F1-score (‚âà 0.93 y 0.96 respectivamente).
Logistic Regression obtuvo un rendimiento casi id√©ntico, mientras que Naive Bayes, aunque m√°s r√°pido, present√≥ un descenso notable en la detecci√≥n de comentarios negativos.

Este comportamiento puede explicarse por la naturaleza lineal del texto TF-IDF: tanto la regresi√≥n log√≠stica como el SVM explotan mejor la estructura de los datos, mientras que Naive Bayes simplifica demasiado las dependencias entre palabras.

Las matrices de confusi√≥n revelaron que el modelo tiende a clasificar err√≥neamente rese√±as negativas como positivas, lo que refleja el desequilibrio del dataset (mayor√≠a de rese√±as con 4 o 5 estrellas).
Aun as√≠, la capacidad del modelo para identificar correctamente las opiniones positivas es sobresaliente, confirmando que el lenguaje entusiasta (‚Äúlove‚Äù, ‚Äúexcellent‚Äù, ‚Äúdelicious‚Äù) tiene patrones muy consistentes.

El an√°lisis de ROC curves confirm√≥ que los tres modelos aprenden correctamente la relaci√≥n entre caracter√≠sticas y etiquetas, aunque SVM y Logistic Regression muestran curvas m√°s altas y estables, indicando una mejor calibraci√≥n en la predicci√≥n.
Las √°reas bajo la curva (AUC) refuerzan esta superioridad: ambos modelos mantienen una tasa de verdaderos positivos alta incluso con umbrales exigentes.

Las visualizaciones mediante t-SNE y TruncatedSVD muestran que las rese√±as positivas y negativas tienden a ocupar regiones diferentes en el espacio vectorial, aunque con cierta superposici√≥n.
Esto sugiere que la polaridad est√° bien representada por las palabras, pero el lenguaje de las rese√±as ‚Äîa menudo informal, ambiguo o mixto‚Äî introduce zonas de intersecci√≥n inevitables.

En conjunto, los resultados demuestran que las opiniones de los consumidores sobre alimentos tienen patrones ling√º√≠sticos claros y detectables mediante t√©cnicas cl√°sicas de Machine Learning.
El pipeline desarrollado, aun sin recurrir a modelos neuronales, logra un desempe√±o s√≥lido, interpretabilidad alta y un balance ideal entre precisi√≥n y eficiencia.
"""